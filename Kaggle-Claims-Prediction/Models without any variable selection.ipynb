{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models built with all the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('data_enc.pkl', 'rb')\n",
    "Xtrain = pickle.load(file)\n",
    "ytrain = pickle.load(file)\n",
    "Xtest = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (188318, 1187)\n",
      "ytrain (188318,)\n",
      "Xtest (125546, 1187)\n"
     ]
    }
   ],
   "source": [
    "print(\"Xtrain\", Xtrain.shape)\n",
    "print(\"ytrain\",ytrain.shape)\n",
    "print(\"Xtest\",Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select small subset for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169486, 1187) (169486,)\n",
      "(18832, 1187) (18832,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1, X2, y1, y2 = train_test_split(Xtrain, ytrain, test_size= 0.1, random_state = SEED)\n",
    "print(X1.shape, y1.shape)\n",
    "print(X2.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models without any feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest parameters\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 600, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 10)]\n",
    "max_depth.append(None)\n",
    "#min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "param_rf = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               #'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 12, 14, 16, 18, 21, 23, 25, 27, 30, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 244, 288, 333, 377, 422, 466, 511, 555, 600]}\n"
     ]
    }
   ],
   "source": [
    "pprint(param_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning using randomized search and 5-fold CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to large dataset and computation restriction, we train the model on a small subset of the data and then fit the model on the whole training data. \n",
    "The fitted model is then evaluated on the held out test data on the kaggle website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "--- 2002.649445772171 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestRegressor(random_state=SEED, oob_score = True, n_jobs = -1)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = param_rf, n_iter = 10, cv = 5, verbose=1, scoring='neg_mean_absolute_error', n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X2, y2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 333, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 27} -0.4533768693104105\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_, rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=27, min_samples_leaf=2, n_estimators=333,\n",
       "                      n_jobs=-1, oob_score=True, random_state=80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor(max_depth=27, min_samples_leaf=2, n_estimators=333, max_features = 'auto',\n",
    "                      n_jobs=-1, oob_score=True, random_state=80)\n",
    "rf2.fit(Xtrain,ytrain)\n",
    "pred_rf = rf2.predict(Xtest)\n",
    "\n",
    "submit_rf = sample_submit\n",
    "submit_rf['loss'] = pred_rf \n",
    "submit_rf.to_csv('submit_rf.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF score on test set Private LB = 3024.03497 -- very bad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD75250>,\n",
      " 'eta': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD79430>,\n",
      " 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD79FD0>,\n",
      " 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD79370>,\n",
      " 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD69C70>,\n",
      " 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016D1AD75A00>}\n"
     ]
    }
   ],
   "source": [
    "param_grid ={'max_depth':randint(3,8),\n",
    "             'min_child_weight':randint(1,6),\n",
    "             'eta':uniform(0.05,0.095),\n",
    "             'subsample': uniform(0.6,0.3) ,\n",
    "             'colsample_bytree': uniform(0.6,0.3),\n",
    "             'n_estimators': randint(200,600)\n",
    "            }\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# xgb = XGBRegressor(n_jobs=-1, objective= 'reg:squarederror',random_state=SEED, verbosity=0)\n",
    "# grid_xgb = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid,n_iter=10, n_jobs=-1, cv=3, scoring='neg_mean_absolute_error',verbose=1)\n",
    "\n",
    "# def xg_eval_mae(y_pred, dtrain):\n",
    "#     y_true = dtrain.get_label()\n",
    "#     mymae = np.mean(abs(np.expm1(y_true)-np.expm1(y_pred)))\n",
    "#     return 'mymae', mymae\n",
    "\n",
    "# grid_xgb.fit(X2,y2,\n",
    "#          eval_set = [(X1,y1)],\n",
    "#          eval_metric = xg_eval_mae,\n",
    "#          early_stopping_rounds = 50, verbose=0)\n",
    "\n",
    "# print(grid_xgb.best_params_, grid_xgb.best_score_)\n",
    "\n",
    "# low on memory - cannot run on pc - kernel keeps restarting/hanging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2b43b8d786a0>,\n",
       "                                        'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2b43b8d94220>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2b43b8d96250>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x2b43b8d942b0>},\n",
       "                   scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_jobs=-1, objective= 'reg:squarederror',random_state=SEED, verbosity=0)\n",
    "grid_xgb = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid,n_iter=10, n_jobs=-1, cv=3, scoring='neg_mean_absolute_error',verbose=1)\n",
    "\n",
    "grid_xgb.fit(X2,y2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.859474115591304, 'eta': 0.0500389156243541, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 440, 'subsample': 0.6471619961876824} -0.4322413940500162\n"
     ]
    }
   ],
   "source": [
    "print(grid_xgb.best_params_, grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.859474115591304,\n",
       "             eta=0.0500389156243541, gamma=0, gpu_id=-1, importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.0500389151,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=5, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=440, n_jobs=-1,\n",
       "             num_parallel_tree=1, random_state=80, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=0.6471619961876824,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2 = XGBRegressor(colsample_bytree=0.859474115591304,\n",
    "             eta=0.0500389156243541, max_depth=6, min_child_weight=5,\n",
    "             n_estimators=440, n_jobs=-1,\n",
    "             random_state=80, reg_alpha=0, reg_lambda=1,\n",
    "             subsample=0.6471619961876824,\n",
    "             verbosity=0)\n",
    "\n",
    "xgb2.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb2.predict(Xtest)\n",
    "\n",
    "submit_xgb = sample_submit\n",
    "submit_xgb['loss'] = np.expm1(pred)\n",
    "submit_xgb.to_csv('submit_xgb2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost score on test set Private LB = 1141.88064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410B20>,\n",
      " 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410F40>,\n",
      " 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410370>,\n",
      " 'num_leaves': [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]}\n"
     ]
    }
   ],
   "source": [
    "param_lgb = {'n_estimators':randint(200,600),\n",
    "              'colsample_bytree': uniform(0.6,0.3),\n",
    "              'learning_rate': uniform(0.05, 0.095),\n",
    "              #'max_depth': [int(x) for x in np.linspace(start = 2, stop = 12, num = 6)],\n",
    "              'num_leaves':[15, 31, 63, 127, 255, 511, 1023, 2047, 4095]}\n",
    "pprint(param_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 58.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[1]\tvalid_0's l1: 0.644159\tvalid_0's mymae: 1777.88\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[2]\tvalid_0's l1: 0.628947\tvalid_0's mymae: 1744.98\n",
      "[3]\tvalid_0's l1: 0.614932\tvalid_0's mymae: 1714.2\n",
      "[4]\tvalid_0's l1: 0.602764\tvalid_0's mymae: 1686.92\n",
      "[5]\tvalid_0's l1: 0.590794\tvalid_0's mymae: 1659.51\n",
      "[6]\tvalid_0's l1: 0.579583\tvalid_0's mymae: 1633.45\n",
      "[7]\tvalid_0's l1: 0.56981\tvalid_0's mymae: 1610.1\n",
      "[8]\tvalid_0's l1: 0.560427\tvalid_0's mymae: 1587.43\n",
      "[9]\tvalid_0's l1: 0.551918\tvalid_0's mymae: 1566.42\n",
      "[10]\tvalid_0's l1: 0.54448\tvalid_0's mymae: 1547.59\n",
      "[11]\tvalid_0's l1: 0.537158\tvalid_0's mymae: 1528.64\n",
      "[12]\tvalid_0's l1: 0.530417\tvalid_0's mymae: 1511.2\n",
      "[13]\tvalid_0's l1: 0.52388\tvalid_0's mymae: 1493.71\n",
      "[14]\tvalid_0's l1: 0.518001\tvalid_0's mymae: 1477.77\n",
      "[15]\tvalid_0's l1: 0.51279\tvalid_0's mymae: 1463.34\n",
      "[16]\tvalid_0's l1: 0.507909\tvalid_0's mymae: 1449.46\n",
      "[17]\tvalid_0's l1: 0.503186\tvalid_0's mymae: 1435.99\n",
      "[18]\tvalid_0's l1: 0.4992\tvalid_0's mymae: 1424.2\n",
      "[19]\tvalid_0's l1: 0.495208\tvalid_0's mymae: 1412.21\n",
      "[20]\tvalid_0's l1: 0.491498\tvalid_0's mymae: 1401.06\n",
      "[21]\tvalid_0's l1: 0.487826\tvalid_0's mymae: 1390.1\n",
      "[22]\tvalid_0's l1: 0.484115\tvalid_0's mymae: 1379.05\n",
      "[23]\tvalid_0's l1: 0.480997\tvalid_0's mymae: 1369.13\n",
      "[24]\tvalid_0's l1: 0.47827\tvalid_0's mymae: 1360.3\n",
      "[25]\tvalid_0's l1: 0.47534\tvalid_0's mymae: 1351.48\n",
      "[26]\tvalid_0's l1: 0.4727\tvalid_0's mymae: 1342.93\n",
      "[27]\tvalid_0's l1: 0.470253\tvalid_0's mymae: 1335.08\n",
      "[28]\tvalid_0's l1: 0.467896\tvalid_0's mymae: 1327.38\n",
      "[29]\tvalid_0's l1: 0.465841\tvalid_0's mymae: 1320.31\n",
      "[30]\tvalid_0's l1: 0.463751\tvalid_0's mymae: 1313.3\n",
      "[31]\tvalid_0's l1: 0.461684\tvalid_0's mymae: 1306.55\n",
      "[32]\tvalid_0's l1: 0.459859\tvalid_0's mymae: 1300.34\n",
      "[33]\tvalid_0's l1: 0.458193\tvalid_0's mymae: 1294.64\n",
      "[34]\tvalid_0's l1: 0.456648\tvalid_0's mymae: 1289.17\n",
      "[35]\tvalid_0's l1: 0.455245\tvalid_0's mymae: 1284.23\n",
      "[36]\tvalid_0's l1: 0.453847\tvalid_0's mymae: 1279.27\n",
      "[37]\tvalid_0's l1: 0.452629\tvalid_0's mymae: 1274.99\n",
      "[38]\tvalid_0's l1: 0.451242\tvalid_0's mymae: 1270.45\n",
      "[39]\tvalid_0's l1: 0.450108\tvalid_0's mymae: 1266.37\n",
      "[40]\tvalid_0's l1: 0.448895\tvalid_0's mymae: 1262.38\n",
      "[41]\tvalid_0's l1: 0.447754\tvalid_0's mymae: 1258.34\n",
      "[42]\tvalid_0's l1: 0.44671\tvalid_0's mymae: 1254.61\n",
      "[43]\tvalid_0's l1: 0.445773\tvalid_0's mymae: 1251.31\n",
      "[44]\tvalid_0's l1: 0.444796\tvalid_0's mymae: 1247.76\n",
      "[45]\tvalid_0's l1: 0.443807\tvalid_0's mymae: 1244.37\n",
      "[46]\tvalid_0's l1: 0.442904\tvalid_0's mymae: 1241.05\n",
      "[47]\tvalid_0's l1: 0.44202\tvalid_0's mymae: 1237.95\n",
      "[48]\tvalid_0's l1: 0.441063\tvalid_0's mymae: 1234.83\n",
      "[49]\tvalid_0's l1: 0.44023\tvalid_0's mymae: 1231.76\n",
      "[50]\tvalid_0's l1: 0.439551\tvalid_0's mymae: 1229.28\n",
      "[51]\tvalid_0's l1: 0.438828\tvalid_0's mymae: 1226.87\n",
      "[52]\tvalid_0's l1: 0.4382\tvalid_0's mymae: 1224.69\n",
      "[53]\tvalid_0's l1: 0.437573\tvalid_0's mymae: 1222.47\n",
      "[54]\tvalid_0's l1: 0.436981\tvalid_0's mymae: 1220.34\n",
      "[55]\tvalid_0's l1: 0.436432\tvalid_0's mymae: 1218.54\n",
      "[56]\tvalid_0's l1: 0.435833\tvalid_0's mymae: 1216.38\n",
      "[57]\tvalid_0's l1: 0.435218\tvalid_0's mymae: 1214.39\n",
      "[58]\tvalid_0's l1: 0.434627\tvalid_0's mymae: 1212.4\n",
      "[59]\tvalid_0's l1: 0.434045\tvalid_0's mymae: 1210.48\n",
      "[60]\tvalid_0's l1: 0.433587\tvalid_0's mymae: 1208.84\n",
      "[61]\tvalid_0's l1: 0.433114\tvalid_0's mymae: 1207.27\n",
      "[62]\tvalid_0's l1: 0.432639\tvalid_0's mymae: 1205.61\n",
      "[63]\tvalid_0's l1: 0.43222\tvalid_0's mymae: 1203.98\n",
      "[64]\tvalid_0's l1: 0.43184\tvalid_0's mymae: 1202.53\n",
      "[65]\tvalid_0's l1: 0.431408\tvalid_0's mymae: 1201.01\n",
      "[66]\tvalid_0's l1: 0.431033\tvalid_0's mymae: 1199.61\n",
      "[67]\tvalid_0's l1: 0.430673\tvalid_0's mymae: 1198.38\n",
      "[68]\tvalid_0's l1: 0.43034\tvalid_0's mymae: 1197.2\n",
      "[69]\tvalid_0's l1: 0.430016\tvalid_0's mymae: 1195.96\n",
      "[70]\tvalid_0's l1: 0.429713\tvalid_0's mymae: 1194.87\n",
      "[71]\tvalid_0's l1: 0.429365\tvalid_0's mymae: 1193.79\n",
      "[72]\tvalid_0's l1: 0.429041\tvalid_0's mymae: 1192.63\n",
      "[73]\tvalid_0's l1: 0.42876\tvalid_0's mymae: 1191.52\n",
      "[74]\tvalid_0's l1: 0.428468\tvalid_0's mymae: 1190.44\n",
      "[75]\tvalid_0's l1: 0.428142\tvalid_0's mymae: 1189.32\n",
      "[76]\tvalid_0's l1: 0.427838\tvalid_0's mymae: 1188.31\n",
      "[77]\tvalid_0's l1: 0.427577\tvalid_0's mymae: 1187.4\n",
      "[78]\tvalid_0's l1: 0.427351\tvalid_0's mymae: 1186.54\n",
      "[79]\tvalid_0's l1: 0.427109\tvalid_0's mymae: 1185.71\n",
      "[80]\tvalid_0's l1: 0.42683\tvalid_0's mymae: 1184.83\n",
      "[81]\tvalid_0's l1: 0.426566\tvalid_0's mymae: 1183.93\n",
      "[82]\tvalid_0's l1: 0.426343\tvalid_0's mymae: 1183.12\n",
      "[83]\tvalid_0's l1: 0.426133\tvalid_0's mymae: 1182.34\n",
      "[84]\tvalid_0's l1: 0.42594\tvalid_0's mymae: 1181.65\n",
      "[85]\tvalid_0's l1: 0.425724\tvalid_0's mymae: 1181.01\n",
      "[86]\tvalid_0's l1: 0.425493\tvalid_0's mymae: 1180.26\n",
      "[87]\tvalid_0's l1: 0.425298\tvalid_0's mymae: 1179.61\n",
      "[88]\tvalid_0's l1: 0.425117\tvalid_0's mymae: 1179.01\n",
      "[89]\tvalid_0's l1: 0.424968\tvalid_0's mymae: 1178.45\n",
      "[90]\tvalid_0's l1: 0.424818\tvalid_0's mymae: 1177.86\n",
      "[91]\tvalid_0's l1: 0.42462\tvalid_0's mymae: 1177.16\n",
      "[92]\tvalid_0's l1: 0.424452\tvalid_0's mymae: 1176.56\n",
      "[93]\tvalid_0's l1: 0.424247\tvalid_0's mymae: 1175.9\n",
      "[94]\tvalid_0's l1: 0.424118\tvalid_0's mymae: 1175.44\n",
      "[95]\tvalid_0's l1: 0.423947\tvalid_0's mymae: 1174.87\n",
      "[96]\tvalid_0's l1: 0.423833\tvalid_0's mymae: 1174.45\n",
      "[97]\tvalid_0's l1: 0.423696\tvalid_0's mymae: 1173.99\n",
      "[98]\tvalid_0's l1: 0.423488\tvalid_0's mymae: 1173.44\n",
      "[99]\tvalid_0's l1: 0.423395\tvalid_0's mymae: 1173.04\n",
      "[100]\tvalid_0's l1: 0.423279\tvalid_0's mymae: 1172.57\n",
      "[101]\tvalid_0's l1: 0.423158\tvalid_0's mymae: 1172.2\n",
      "[102]\tvalid_0's l1: 0.423004\tvalid_0's mymae: 1171.68\n",
      "[103]\tvalid_0's l1: 0.422849\tvalid_0's mymae: 1171.2\n",
      "[104]\tvalid_0's l1: 0.422748\tvalid_0's mymae: 1170.85\n",
      "[105]\tvalid_0's l1: 0.422668\tvalid_0's mymae: 1170.52\n",
      "[106]\tvalid_0's l1: 0.42255\tvalid_0's mymae: 1170.16\n",
      "[107]\tvalid_0's l1: 0.422485\tvalid_0's mymae: 1169.92\n",
      "[108]\tvalid_0's l1: 0.422391\tvalid_0's mymae: 1169.61\n",
      "[109]\tvalid_0's l1: 0.422257\tvalid_0's mymae: 1169.24\n",
      "[110]\tvalid_0's l1: 0.42215\tvalid_0's mymae: 1168.97\n",
      "[111]\tvalid_0's l1: 0.422083\tvalid_0's mymae: 1168.75\n",
      "[112]\tvalid_0's l1: 0.421996\tvalid_0's mymae: 1168.46\n",
      "[113]\tvalid_0's l1: 0.421865\tvalid_0's mymae: 1168.08\n",
      "[114]\tvalid_0's l1: 0.421783\tvalid_0's mymae: 1167.77\n",
      "[115]\tvalid_0's l1: 0.421696\tvalid_0's mymae: 1167.51\n",
      "[116]\tvalid_0's l1: 0.421597\tvalid_0's mymae: 1167.2\n",
      "[117]\tvalid_0's l1: 0.421515\tvalid_0's mymae: 1166.88\n",
      "[118]\tvalid_0's l1: 0.421417\tvalid_0's mymae: 1166.52\n",
      "[119]\tvalid_0's l1: 0.421331\tvalid_0's mymae: 1166.23\n",
      "[120]\tvalid_0's l1: 0.421216\tvalid_0's mymae: 1165.79\n",
      "[121]\tvalid_0's l1: 0.42115\tvalid_0's mymae: 1165.54\n",
      "[122]\tvalid_0's l1: 0.421033\tvalid_0's mymae: 1165.06\n",
      "[123]\tvalid_0's l1: 0.420939\tvalid_0's mymae: 1164.78\n",
      "[124]\tvalid_0's l1: 0.420878\tvalid_0's mymae: 1164.58\n",
      "[125]\tvalid_0's l1: 0.420816\tvalid_0's mymae: 1164.39\n",
      "[126]\tvalid_0's l1: 0.420728\tvalid_0's mymae: 1164.06\n",
      "[127]\tvalid_0's l1: 0.420658\tvalid_0's mymae: 1163.88\n",
      "[128]\tvalid_0's l1: 0.420606\tvalid_0's mymae: 1163.72\n",
      "[129]\tvalid_0's l1: 0.420532\tvalid_0's mymae: 1163.36\n",
      "[130]\tvalid_0's l1: 0.420451\tvalid_0's mymae: 1163.09\n",
      "[131]\tvalid_0's l1: 0.420412\tvalid_0's mymae: 1162.9\n",
      "[132]\tvalid_0's l1: 0.420354\tvalid_0's mymae: 1162.71\n",
      "[133]\tvalid_0's l1: 0.420271\tvalid_0's mymae: 1162.33\n",
      "[134]\tvalid_0's l1: 0.420222\tvalid_0's mymae: 1162.18\n",
      "[135]\tvalid_0's l1: 0.420142\tvalid_0's mymae: 1161.94\n",
      "[136]\tvalid_0's l1: 0.420082\tvalid_0's mymae: 1161.75\n",
      "[137]\tvalid_0's l1: 0.420014\tvalid_0's mymae: 1161.4\n",
      "[138]\tvalid_0's l1: 0.419935\tvalid_0's mymae: 1161.06\n",
      "[139]\tvalid_0's l1: 0.419869\tvalid_0's mymae: 1160.8\n",
      "[140]\tvalid_0's l1: 0.419818\tvalid_0's mymae: 1160.67\n",
      "[141]\tvalid_0's l1: 0.419788\tvalid_0's mymae: 1160.57\n",
      "[142]\tvalid_0's l1: 0.419725\tvalid_0's mymae: 1160.41\n",
      "[143]\tvalid_0's l1: 0.419692\tvalid_0's mymae: 1160.27\n",
      "[144]\tvalid_0's l1: 0.41966\tvalid_0's mymae: 1160.21\n",
      "[145]\tvalid_0's l1: 0.419596\tvalid_0's mymae: 1159.91\n",
      "[146]\tvalid_0's l1: 0.419563\tvalid_0's mymae: 1159.76\n",
      "[147]\tvalid_0's l1: 0.419529\tvalid_0's mymae: 1159.66\n",
      "[148]\tvalid_0's l1: 0.419482\tvalid_0's mymae: 1159.5\n",
      "[149]\tvalid_0's l1: 0.419469\tvalid_0's mymae: 1159.42\n",
      "[150]\tvalid_0's l1: 0.419436\tvalid_0's mymae: 1159.34\n",
      "[151]\tvalid_0's l1: 0.419414\tvalid_0's mymae: 1159.28\n",
      "[152]\tvalid_0's l1: 0.419366\tvalid_0's mymae: 1159.1\n",
      "[153]\tvalid_0's l1: 0.419335\tvalid_0's mymae: 1158.98\n",
      "[154]\tvalid_0's l1: 0.41932\tvalid_0's mymae: 1158.9\n",
      "[155]\tvalid_0's l1: 0.419304\tvalid_0's mymae: 1158.82\n",
      "[156]\tvalid_0's l1: 0.419272\tvalid_0's mymae: 1158.67\n",
      "[157]\tvalid_0's l1: 0.41925\tvalid_0's mymae: 1158.59\n",
      "[158]\tvalid_0's l1: 0.419192\tvalid_0's mymae: 1158.34\n",
      "[159]\tvalid_0's l1: 0.419145\tvalid_0's mymae: 1158.18\n",
      "[160]\tvalid_0's l1: 0.419108\tvalid_0's mymae: 1158.09\n",
      "[161]\tvalid_0's l1: 0.419068\tvalid_0's mymae: 1157.85\n",
      "[162]\tvalid_0's l1: 0.419023\tvalid_0's mymae: 1157.74\n",
      "[163]\tvalid_0's l1: 0.418986\tvalid_0's mymae: 1157.56\n",
      "[164]\tvalid_0's l1: 0.418957\tvalid_0's mymae: 1157.48\n",
      "[165]\tvalid_0's l1: 0.418938\tvalid_0's mymae: 1157.42\n",
      "[166]\tvalid_0's l1: 0.418896\tvalid_0's mymae: 1157.31\n",
      "[167]\tvalid_0's l1: 0.418865\tvalid_0's mymae: 1157.13\n",
      "[168]\tvalid_0's l1: 0.418867\tvalid_0's mymae: 1157.12\n",
      "[169]\tvalid_0's l1: 0.418847\tvalid_0's mymae: 1157.04\n",
      "[170]\tvalid_0's l1: 0.418842\tvalid_0's mymae: 1157.03\n",
      "[171]\tvalid_0's l1: 0.418832\tvalid_0's mymae: 1156.99\n",
      "[172]\tvalid_0's l1: 0.418812\tvalid_0's mymae: 1156.93\n",
      "[173]\tvalid_0's l1: 0.418817\tvalid_0's mymae: 1156.93\n",
      "[174]\tvalid_0's l1: 0.418807\tvalid_0's mymae: 1156.9\n",
      "[175]\tvalid_0's l1: 0.418803\tvalid_0's mymae: 1156.87\n",
      "[176]\tvalid_0's l1: 0.418783\tvalid_0's mymae: 1156.78\n",
      "[177]\tvalid_0's l1: 0.418773\tvalid_0's mymae: 1156.74\n",
      "[178]\tvalid_0's l1: 0.41875\tvalid_0's mymae: 1156.65\n",
      "[179]\tvalid_0's l1: 0.41873\tvalid_0's mymae: 1156.6\n",
      "[180]\tvalid_0's l1: 0.418729\tvalid_0's mymae: 1156.59\n",
      "[181]\tvalid_0's l1: 0.418725\tvalid_0's mymae: 1156.6\n",
      "[182]\tvalid_0's l1: 0.418702\tvalid_0's mymae: 1156.49\n",
      "[183]\tvalid_0's l1: 0.418685\tvalid_0's mymae: 1156.44\n",
      "[184]\tvalid_0's l1: 0.418666\tvalid_0's mymae: 1156.39\n",
      "[185]\tvalid_0's l1: 0.418634\tvalid_0's mymae: 1156.22\n",
      "[186]\tvalid_0's l1: 0.418631\tvalid_0's mymae: 1156.21\n",
      "[187]\tvalid_0's l1: 0.418611\tvalid_0's mymae: 1156.1\n",
      "[188]\tvalid_0's l1: 0.418599\tvalid_0's mymae: 1156.04\n",
      "[189]\tvalid_0's l1: 0.418584\tvalid_0's mymae: 1156.01\n",
      "[190]\tvalid_0's l1: 0.418571\tvalid_0's mymae: 1155.95\n",
      "[191]\tvalid_0's l1: 0.418566\tvalid_0's mymae: 1155.95\n",
      "[192]\tvalid_0's l1: 0.418557\tvalid_0's mymae: 1155.94\n",
      "[193]\tvalid_0's l1: 0.418551\tvalid_0's mymae: 1155.92\n",
      "[194]\tvalid_0's l1: 0.418535\tvalid_0's mymae: 1155.87\n",
      "[195]\tvalid_0's l1: 0.418532\tvalid_0's mymae: 1155.85\n",
      "[196]\tvalid_0's l1: 0.418516\tvalid_0's mymae: 1155.77\n",
      "[197]\tvalid_0's l1: 0.418517\tvalid_0's mymae: 1155.79\n",
      "[198]\tvalid_0's l1: 0.418507\tvalid_0's mymae: 1155.76\n",
      "[199]\tvalid_0's l1: 0.418499\tvalid_0's mymae: 1155.73\n",
      "[200]\tvalid_0's l1: 0.418503\tvalid_0's mymae: 1155.74\n",
      "[201]\tvalid_0's l1: 0.418497\tvalid_0's mymae: 1155.72\n",
      "[202]\tvalid_0's l1: 0.418491\tvalid_0's mymae: 1155.71\n",
      "[203]\tvalid_0's l1: 0.418488\tvalid_0's mymae: 1155.71\n",
      "[204]\tvalid_0's l1: 0.41847\tvalid_0's mymae: 1155.6\n",
      "[205]\tvalid_0's l1: 0.418465\tvalid_0's mymae: 1155.56\n",
      "[206]\tvalid_0's l1: 0.418444\tvalid_0's mymae: 1155.46\n",
      "[207]\tvalid_0's l1: 0.41843\tvalid_0's mymae: 1155.42\n",
      "[208]\tvalid_0's l1: 0.418404\tvalid_0's mymae: 1155.35\n",
      "[209]\tvalid_0's l1: 0.418402\tvalid_0's mymae: 1155.35\n",
      "[210]\tvalid_0's l1: 0.418402\tvalid_0's mymae: 1155.36\n",
      "[211]\tvalid_0's l1: 0.418401\tvalid_0's mymae: 1155.36\n",
      "[212]\tvalid_0's l1: 0.418392\tvalid_0's mymae: 1155.33\n",
      "[213]\tvalid_0's l1: 0.418389\tvalid_0's mymae: 1155.3\n",
      "[214]\tvalid_0's l1: 0.418382\tvalid_0's mymae: 1155.28\n",
      "[215]\tvalid_0's l1: 0.418383\tvalid_0's mymae: 1155.27\n",
      "[216]\tvalid_0's l1: 0.418385\tvalid_0's mymae: 1155.29\n",
      "[217]\tvalid_0's l1: 0.418382\tvalid_0's mymae: 1155.29\n",
      "[218]\tvalid_0's l1: 0.418389\tvalid_0's mymae: 1155.31\n",
      "[219]\tvalid_0's l1: 0.418388\tvalid_0's mymae: 1155.3\n",
      "[220]\tvalid_0's l1: 0.41839\tvalid_0's mymae: 1155.29\n",
      "[221]\tvalid_0's l1: 0.418376\tvalid_0's mymae: 1155.24\n",
      "[222]\tvalid_0's l1: 0.418367\tvalid_0's mymae: 1155.23\n",
      "[223]\tvalid_0's l1: 0.418354\tvalid_0's mymae: 1155.17\n",
      "[224]\tvalid_0's l1: 0.418335\tvalid_0's mymae: 1155.09\n",
      "[225]\tvalid_0's l1: 0.418329\tvalid_0's mymae: 1155.08\n",
      "[226]\tvalid_0's l1: 0.418316\tvalid_0's mymae: 1155.05\n",
      "[227]\tvalid_0's l1: 0.418303\tvalid_0's mymae: 1154.98\n",
      "[228]\tvalid_0's l1: 0.418303\tvalid_0's mymae: 1154.98\n",
      "[229]\tvalid_0's l1: 0.418297\tvalid_0's mymae: 1154.94\n",
      "[230]\tvalid_0's l1: 0.418296\tvalid_0's mymae: 1154.94\n",
      "[231]\tvalid_0's l1: 0.418288\tvalid_0's mymae: 1154.92\n",
      "[232]\tvalid_0's l1: 0.418283\tvalid_0's mymae: 1154.88\n",
      "[233]\tvalid_0's l1: 0.418278\tvalid_0's mymae: 1154.86\n",
      "[234]\tvalid_0's l1: 0.418263\tvalid_0's mymae: 1154.81\n",
      "[235]\tvalid_0's l1: 0.418254\tvalid_0's mymae: 1154.8\n",
      "[236]\tvalid_0's l1: 0.41825\tvalid_0's mymae: 1154.78\n",
      "[237]\tvalid_0's l1: 0.418247\tvalid_0's mymae: 1154.77\n",
      "[238]\tvalid_0's l1: 0.418241\tvalid_0's mymae: 1154.75\n",
      "[239]\tvalid_0's l1: 0.418236\tvalid_0's mymae: 1154.73\n",
      "[240]\tvalid_0's l1: 0.418207\tvalid_0's mymae: 1154.53\n",
      "[241]\tvalid_0's l1: 0.418204\tvalid_0's mymae: 1154.48\n",
      "[242]\tvalid_0's l1: 0.418199\tvalid_0's mymae: 1154.48\n",
      "[243]\tvalid_0's l1: 0.418194\tvalid_0's mymae: 1154.46\n",
      "[244]\tvalid_0's l1: 0.418202\tvalid_0's mymae: 1154.48\n",
      "[245]\tvalid_0's l1: 0.418185\tvalid_0's mymae: 1154.43\n",
      "[246]\tvalid_0's l1: 0.418183\tvalid_0's mymae: 1154.43\n",
      "[247]\tvalid_0's l1: 0.41818\tvalid_0's mymae: 1154.41\n",
      "[248]\tvalid_0's l1: 0.418168\tvalid_0's mymae: 1154.38\n",
      "[249]\tvalid_0's l1: 0.418143\tvalid_0's mymae: 1154.26\n",
      "[250]\tvalid_0's l1: 0.418143\tvalid_0's mymae: 1154.24\n",
      "[251]\tvalid_0's l1: 0.41813\tvalid_0's mymae: 1154.21\n",
      "[252]\tvalid_0's l1: 0.418132\tvalid_0's mymae: 1154.22\n",
      "[253]\tvalid_0's l1: 0.418135\tvalid_0's mymae: 1154.25\n",
      "[254]\tvalid_0's l1: 0.418139\tvalid_0's mymae: 1154.24\n",
      "[255]\tvalid_0's l1: 0.418145\tvalid_0's mymae: 1154.24\n",
      "[256]\tvalid_0's l1: 0.41815\tvalid_0's mymae: 1154.25\n",
      "[257]\tvalid_0's l1: 0.418136\tvalid_0's mymae: 1154.2\n",
      "[258]\tvalid_0's l1: 0.418138\tvalid_0's mymae: 1154.2\n",
      "[259]\tvalid_0's l1: 0.418117\tvalid_0's mymae: 1154.13\n",
      "[260]\tvalid_0's l1: 0.418116\tvalid_0's mymae: 1154.1\n",
      "[261]\tvalid_0's l1: 0.418102\tvalid_0's mymae: 1154.06\n",
      "[262]\tvalid_0's l1: 0.418094\tvalid_0's mymae: 1154.03\n",
      "[263]\tvalid_0's l1: 0.418091\tvalid_0's mymae: 1154.02\n",
      "[264]\tvalid_0's l1: 0.418082\tvalid_0's mymae: 1153.99\n",
      "[265]\tvalid_0's l1: 0.418077\tvalid_0's mymae: 1153.97\n",
      "[266]\tvalid_0's l1: 0.418068\tvalid_0's mymae: 1153.96\n",
      "[267]\tvalid_0's l1: 0.418068\tvalid_0's mymae: 1153.96\n",
      "[268]\tvalid_0's l1: 0.418066\tvalid_0's mymae: 1153.95\n",
      "[269]\tvalid_0's l1: 0.418056\tvalid_0's mymae: 1153.93\n",
      "[270]\tvalid_0's l1: 0.41805\tvalid_0's mymae: 1153.9\n",
      "[271]\tvalid_0's l1: 0.418046\tvalid_0's mymae: 1153.89\n",
      "[272]\tvalid_0's l1: 0.418038\tvalid_0's mymae: 1153.85\n",
      "[273]\tvalid_0's l1: 0.418036\tvalid_0's mymae: 1153.84\n",
      "[274]\tvalid_0's l1: 0.418028\tvalid_0's mymae: 1153.82\n",
      "[275]\tvalid_0's l1: 0.418022\tvalid_0's mymae: 1153.79\n",
      "[276]\tvalid_0's l1: 0.418014\tvalid_0's mymae: 1153.77\n",
      "[277]\tvalid_0's l1: 0.418002\tvalid_0's mymae: 1153.73\n",
      "[278]\tvalid_0's l1: 0.417991\tvalid_0's mymae: 1153.69\n",
      "[279]\tvalid_0's l1: 0.417979\tvalid_0's mymae: 1153.64\n",
      "[280]\tvalid_0's l1: 0.417974\tvalid_0's mymae: 1153.63\n",
      "[281]\tvalid_0's l1: 0.417978\tvalid_0's mymae: 1153.64\n",
      "[282]\tvalid_0's l1: 0.41797\tvalid_0's mymae: 1153.63\n",
      "[283]\tvalid_0's l1: 0.417969\tvalid_0's mymae: 1153.64\n",
      "[284]\tvalid_0's l1: 0.417969\tvalid_0's mymae: 1153.66\n",
      "[285]\tvalid_0's l1: 0.417957\tvalid_0's mymae: 1153.62\n",
      "[286]\tvalid_0's l1: 0.417954\tvalid_0's mymae: 1153.62\n",
      "[287]\tvalid_0's l1: 0.417953\tvalid_0's mymae: 1153.61\n",
      "[288]\tvalid_0's l1: 0.417955\tvalid_0's mymae: 1153.64\n",
      "[289]\tvalid_0's l1: 0.417955\tvalid_0's mymae: 1153.64\n",
      "[290]\tvalid_0's l1: 0.417946\tvalid_0's mymae: 1153.59\n",
      "[291]\tvalid_0's l1: 0.417944\tvalid_0's mymae: 1153.58\n",
      "[292]\tvalid_0's l1: 0.417941\tvalid_0's mymae: 1153.57\n",
      "[293]\tvalid_0's l1: 0.417925\tvalid_0's mymae: 1153.52\n",
      "[294]\tvalid_0's l1: 0.417922\tvalid_0's mymae: 1153.51\n",
      "[295]\tvalid_0's l1: 0.41792\tvalid_0's mymae: 1153.5\n",
      "[296]\tvalid_0's l1: 0.417922\tvalid_0's mymae: 1153.5\n",
      "[297]\tvalid_0's l1: 0.417932\tvalid_0's mymae: 1153.52\n",
      "[298]\tvalid_0's l1: 0.417926\tvalid_0's mymae: 1153.49\n",
      "[299]\tvalid_0's l1: 0.417918\tvalid_0's mymae: 1153.46\n",
      "[300]\tvalid_0's l1: 0.417914\tvalid_0's mymae: 1153.44\n",
      "[301]\tvalid_0's l1: 0.41791\tvalid_0's mymae: 1153.42\n",
      "[302]\tvalid_0's l1: 0.417909\tvalid_0's mymae: 1153.43\n",
      "[303]\tvalid_0's l1: 0.417906\tvalid_0's mymae: 1153.44\n",
      "[304]\tvalid_0's l1: 0.417896\tvalid_0's mymae: 1153.4\n",
      "[305]\tvalid_0's l1: 0.41789\tvalid_0's mymae: 1153.38\n",
      "[306]\tvalid_0's l1: 0.417888\tvalid_0's mymae: 1153.38\n",
      "[307]\tvalid_0's l1: 0.417886\tvalid_0's mymae: 1153.38\n",
      "[308]\tvalid_0's l1: 0.417883\tvalid_0's mymae: 1153.37\n",
      "[309]\tvalid_0's l1: 0.417881\tvalid_0's mymae: 1153.36\n",
      "[310]\tvalid_0's l1: 0.417881\tvalid_0's mymae: 1153.38\n",
      "[311]\tvalid_0's l1: 0.41788\tvalid_0's mymae: 1153.37\n",
      "[312]\tvalid_0's l1: 0.417882\tvalid_0's mymae: 1153.38\n",
      "[313]\tvalid_0's l1: 0.41788\tvalid_0's mymae: 1153.37\n",
      "[314]\tvalid_0's l1: 0.41788\tvalid_0's mymae: 1153.35\n",
      "[315]\tvalid_0's l1: 0.41788\tvalid_0's mymae: 1153.36\n",
      "[316]\tvalid_0's l1: 0.417879\tvalid_0's mymae: 1153.34\n",
      "[317]\tvalid_0's l1: 0.41788\tvalid_0's mymae: 1153.34\n",
      "[318]\tvalid_0's l1: 0.417882\tvalid_0's mymae: 1153.34\n",
      "[319]\tvalid_0's l1: 0.417883\tvalid_0's mymae: 1153.35\n",
      "[320]\tvalid_0's l1: 0.417881\tvalid_0's mymae: 1153.34\n",
      "[321]\tvalid_0's l1: 0.417881\tvalid_0's mymae: 1153.33\n",
      "[322]\tvalid_0's l1: 0.417879\tvalid_0's mymae: 1153.33\n",
      "[323]\tvalid_0's l1: 0.417876\tvalid_0's mymae: 1153.33\n",
      "[324]\tvalid_0's l1: 0.417876\tvalid_0's mymae: 1153.32\n",
      "[325]\tvalid_0's l1: 0.417874\tvalid_0's mymae: 1153.31\n",
      "[326]\tvalid_0's l1: 0.417865\tvalid_0's mymae: 1153.29\n",
      "[327]\tvalid_0's l1: 0.417858\tvalid_0's mymae: 1153.28\n",
      "[328]\tvalid_0's l1: 0.417857\tvalid_0's mymae: 1153.28\n",
      "[329]\tvalid_0's l1: 0.417852\tvalid_0's mymae: 1153.25\n",
      "[330]\tvalid_0's l1: 0.417839\tvalid_0's mymae: 1153.24\n",
      "[331]\tvalid_0's l1: 0.417841\tvalid_0's mymae: 1153.24\n",
      "[332]\tvalid_0's l1: 0.417837\tvalid_0's mymae: 1153.25\n",
      "[333]\tvalid_0's l1: 0.417831\tvalid_0's mymae: 1153.22\n",
      "[334]\tvalid_0's l1: 0.417836\tvalid_0's mymae: 1153.24\n",
      "[335]\tvalid_0's l1: 0.417839\tvalid_0's mymae: 1153.25\n",
      "[336]\tvalid_0's l1: 0.417841\tvalid_0's mymae: 1153.27\n",
      "[337]\tvalid_0's l1: 0.417841\tvalid_0's mymae: 1153.27\n",
      "[338]\tvalid_0's l1: 0.417837\tvalid_0's mymae: 1153.22\n",
      "[339]\tvalid_0's l1: 0.417846\tvalid_0's mymae: 1153.23\n",
      "[340]\tvalid_0's l1: 0.417845\tvalid_0's mymae: 1153.24\n",
      "[341]\tvalid_0's l1: 0.417848\tvalid_0's mymae: 1153.22\n",
      "[342]\tvalid_0's l1: 0.417845\tvalid_0's mymae: 1153.21\n",
      "[343]\tvalid_0's l1: 0.417843\tvalid_0's mymae: 1153.21\n",
      "[344]\tvalid_0's l1: 0.417841\tvalid_0's mymae: 1153.22\n",
      "[345]\tvalid_0's l1: 0.417851\tvalid_0's mymae: 1153.25\n",
      "[346]\tvalid_0's l1: 0.417856\tvalid_0's mymae: 1153.27\n",
      "[347]\tvalid_0's l1: 0.417853\tvalid_0's mymae: 1153.25\n",
      "[348]\tvalid_0's l1: 0.417852\tvalid_0's mymae: 1153.26\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's l1: 0.417831\tvalid_0's mymae: 1153.22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=LGBMRegressor(objective='regression_l1',\n",
       "                                           random_state=80, verbosity=0),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410B20>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410F40>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001FD57410370>,\n",
       "                                        'num_leaves': [15, 31, 63, 127, 255,\n",
       "                                                       511, 1023, 2047, 4095]},\n",
       "                   scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(objective='regression_l1', random_state=SEED, n_jobs = -1, verbosity=0)\n",
    "grid_lg = RandomizedSearchCV(estimator=lgbm, param_distributions=param_lgb,n_iter=100, n_jobs=-1, cv=3, scoring='neg_mean_absolute_error',verbose=1)\n",
    "\n",
    "def eval_mae(y_true, y_pred):\n",
    "    mymae = np.mean(abs(np.expm1(y_true)-np.expm1(y_pred)))\n",
    "    return 'mymae', mymae, False\n",
    "\n",
    "grid_lg.fit(X2, y2, \n",
    "         eval_set = [(X1,y1)],\n",
    "         eval_metric = eval_mae,\n",
    "         early_stopping_rounds = 15\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6490660531637237, 'learning_rate': 0.057683251484169334, 'n_estimators': 597, 'num_leaves': 63} -0.4177918978206256\n"
     ]
    }
   ],
   "source": [
    "print(grid_lg.best_params_, grid_lg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.6490660531637237,\n",
       "              learning_rate=0.057683251484169334, n_estimators=597,\n",
       "              num_leaves=63, objective='regression_l1', random_state=80,\n",
       "              verbosity=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pprint(grid_lg.cv_results_['params'])\n",
    "#pprint(grid_lg.cv_results_['mean_test_score'])\n",
    "grid_lg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.6490660531637237,\n",
       "              learning_rate=0.057683251484169334, n_estimators=597,\n",
       "              num_leaves=63, objective='regression_l1', random_state=80,\n",
       "              verbosity=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm2 = LGBMRegressor(colsample_bytree=0.6490660531637237,\n",
    "              learning_rate=0.057683251484169334, n_estimators=597,\n",
    "              num_leaves=63, objective='regression_l1', random_state=80,\n",
    "              verbosity=0)\n",
    "lgbm2.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgbm2.predict(Xtest, num_iteration = lgbm2.best_iteration_)\n",
    "\n",
    "submit_lgbm = sample_submit\n",
    "submit_lgbm['loss'] = np.expm1(pred)\n",
    "submit_lgbm.to_csv('submit_lgbm2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM score on test set Private LB = 1133.77977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost and LightGBM have similar performance but LightGBM trains much faster than XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set - Private LB\n",
      "\n",
      "\n",
      "Model              MAE\n",
      "-------------  -------\n",
      "Random Forest  3024.03\n",
      "XGBoost        1141.88\n",
      "LightGBM       1133.78\n"
     ]
    }
   ],
   "source": [
    "print('Score on test set - Private LB')\n",
    "print('\\n')\n",
    "from tabulate import tabulate\n",
    "print(tabulate( [ ['Random Forest', 3024.03497], ['XGBoost',1141.88064], ['LightGBM' ,1133.77977] ] , headers=['Model', 'MAE']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
